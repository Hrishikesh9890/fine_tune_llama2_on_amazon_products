Llama 2 is a large language model (LLM) developed by Meta AI. It has models ranging from 7 billion to 70 billion parameters trained on 2 trillion tokens of web data.
Llama 2 outperforms other open-source LLMs on many external benchmarks, including reasoning, coding, proficiency, and knowledge tests. Also it comes with larger context window of 4k tokens.

The main focus of jupyter notebook lies in the step-by-step guide on how to fine-tune LLama 2 LLM model on your very own custom dataset! Using a freely available single-node GPU on Colab,
we'll walk you through the entire process, making it accessible to everyone.

ðŸ”§ To make things more tangible, we'll showcase a practical example using the amazon products Dataset.
